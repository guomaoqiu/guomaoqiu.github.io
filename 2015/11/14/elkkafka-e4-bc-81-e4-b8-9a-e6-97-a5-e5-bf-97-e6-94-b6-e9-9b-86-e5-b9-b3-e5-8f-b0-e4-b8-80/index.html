<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>ELK+Kafka 企业日志收集平台(一) | OpsThoughts</title><meta name="author" content="NoardGuo-Ops"><meta name="copyright" content="NoardGuo-Ops"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="背景：最近线上上了ELK，但是只用了一台Redis在中间作为消息队列，以减轻前端es集群的压力，Redis的集群解决方案暂时没有接触过，并且Redis作为消息队列并不是它的强项；所以最近将Redis换成了专业的消息信息发布订阅系统Kafka, Kafka的更多介绍大家可以看这里：传送门&nbsp; ,关于ELK的知识网上有很多的哦，&nbsp;此篇博客主要是总结一下目前线上这个平台的实施步骤，EL">
<meta property="og:type" content="article">
<meta property="og:title" content="ELK+Kafka 企业日志收集平台(一)">
<meta property="og:url" content="https://blog.sctux.cc/2015/11/14/elkkafka-e4-bc-81-e4-b8-9a-e6-97-a5-e5-bf-97-e6-94-b6-e9-9b-86-e5-b9-b3-e5-8f-b0-e4-b8-80/index.html">
<meta property="og:site_name" content="OpsThoughts">
<meta property="og:description" content="背景：最近线上上了ELK，但是只用了一台Redis在中间作为消息队列，以减轻前端es集群的压力，Redis的集群解决方案暂时没有接触过，并且Redis作为消息队列并不是它的强项；所以最近将Redis换成了专业的消息信息发布订阅系统Kafka, Kafka的更多介绍大家可以看这里：传送门&nbsp; ,关于ELK的知识网上有很多的哦，&nbsp;此篇博客主要是总结一下目前线上这个平台的实施步骤，EL">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800&h=400">
<meta property="article:published_time" content="2015-11-14T08:48:45.000Z">
<meta property="article:modified_time" content="2025-09-01T01:59:08.877Z">
<meta property="article:author" content="NoardGuo-Ops">
<meta property="article:tag" content="ELK">
<meta property="article:tag" content="kafka">
<meta property="article:tag" content="zookeeper">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800&h=400"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "ELK+Kafka 企业日志收集平台(一)",
  "url": "https://blog.sctux.cc/2015/11/14/elkkafka-e4-bc-81-e4-b8-9a-e6-97-a5-e5-bf-97-e6-94-b6-e9-9b-86-e5-b9-b3-e5-8f-b0-e4-b8-80/",
  "image": "https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800&h=400",
  "datePublished": "2015-11-14T08:48:45.000Z",
  "dateModified": "2025-09-01T01:59:08.877Z",
  "author": [
    {
      "@type": "Person",
      "name": "NoardGuo-Ops",
      "url": "https://blog.sctux.cc"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://blog.sctux.cc/2015/11/14/elkkafka-e4-bc-81-e4-b8-9a-e6-97-a5-e5-bf-97-e6-94-b6-e9-9b-86-e5-b9-b3-e5-8f-b0-e4-b8-80/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'ELK+Kafka 企业日志收集平台(一)',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="OpsThoughts" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      if ($loadingBox.classList.contains('loaded')) return
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()

  if (document.readyState === 'complete') {
    preloader.endLoading()
  } else {
    window.addEventListener('load', preloader.endLoading)
    document.addEventListener('DOMContentLoaded', preloader.endLoading)
    // Add timeout protection: force end after 7 seconds
    setTimeout(preloader.endLoading, 7000)
  }

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">99</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">93</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">30</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/works/"><i class="fa-fw fas fa-folder-open"></i><span> 作品</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800&amp;h=400);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">OpsThoughts</span></a><a class="nav-page-title" href="/"><span class="site-name">ELK+Kafka 企业日志收集平台(一)</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/works/"><i class="fa-fw fas fa-folder-open"></i><span> 作品</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">ELK+Kafka 企业日志收集平台(一)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2015-11-14T08:48:45.000Z" title="发表于 2015-11-14 16:48:45">2015-11-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-01T01:59:08.877Z" title="更新于 2025-09-01 09:59:08">2025-09-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E7%BB%B4/">自动化运维</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h3 id="背景："><a href="#背景：" class="headerlink" title="背景："></a><strong>背景：</strong></h3><p>最近线上上了ELK，但是只用了一台Redis在中间作为消息队列，以减轻前端es集群的压力，Redis的集群解决方案暂时没有接触过，并且Redis作为消息队列并不是它的强项；所以最近将Redis换成了专业的消息信息发布订阅系统Kafka, Kafka的更多介绍大家可以看这里：<a href="http://blog.csdn.net/lizhitao/article/details/39499283">传送门</a>&nbsp; ,关于ELK的知识网上有很多的哦，&nbsp;此篇博客主要是总结一下目前线上这个平台的实施步骤，ELK是怎么跟Kafka结合起来的。好吧，动手！</p>
<h3 id="ELK架构拓扑："><a href="#ELK架构拓扑：" class="headerlink" title="ELK架构拓扑："></a><strong>ELK架构拓扑：</strong></h3><p>然而我这里的整个日志收集平台就是这样的拓扑： <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/1.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/1.png" alt="1"></a> 1，使用一台Nginx代理访问kibana的请求; 2，两台es组成es集群，并且在两台es上面都安装kibana;（以下对elasticsearch简称es） 3，中间三台服务器就是我的kafka(zookeeper)集群啦; 上面写的消费者/生产者这是kafka(zookeeper)中的概念; 4，最后面的就是一大堆的生产服务器啦，上面使用的是logstash，当然除了logstash也可以使用其他的工具来收集你的应用程序的日志，例如：Flume，Scribe，Rsyslog，Scripts…… <strong>角色：</strong> <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/11111.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/11111.png" alt="11111"></a> <strong>软件选用：</strong></p>
<p>elasticsearch-1.7.3.tar.gz #这里需要说明一下，前几天使用了最新的elasticsearch2.0，java-1.8.0报错，目前未找到原因，故这里使用1.7.3版本<br>Logstash-2.0.0.tar.gz<br>kibana-4.1.2-linux-x64.tar.gz<br>以上软件都可以从官网下载:<a href="https://www.elastic.co/downloads">https://www.elastic.co/downloads</a></p>
<p>java-1.8.0，nginx采用yum安装</p>
<p><strong>部署步骤：</strong> 1.ES集群安装配置; 2.Logstash客户端配置(直接写入数据到ES集群，写入系统messages日志); 3.Kafka(zookeeper)集群配置;(Logstash写入数据到Kafka消息系统); 4.Kibana部署; 5.Nginx负载均衡Kibana请求; 6.案例：nginx日志收集以及MySQL慢日志收集; 7.Kibana报表基本使用;</p>
<h3 id="ES集群安装配置"><a href="#ES集群安装配置" class="headerlink" title="ES集群安装配置;"></a>ES集群安装配置;</h3><p>es1.example.com: 1.安装java-1.8.0以及依赖包</p>
<p>yum install -y epel-release<br>yum install -y java-1.8.0 git wget lrzsz</p>
<p>2.获取es软件包</p>
<p>wget <a href="https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.7.3.tar.gz">https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.7.3.tar.gz</a><br>tar -xf elasticsearch-1.7.3.tar.gz -C /usr/local<br>ln -sv /usr/local/elasticsearch-1.7.3 /usr/local/elasticsearch</p>
<p>3.修改配置文件</p>
<p>[root@es1 ~]# vim /usr/local/elasticsearch/config/elasticsearch.yml<br>32 cluster.name: es-cluster                         #组播的名称地址<br>40 node.name: “es-node1 “                           #节点名称，不能和其他节点重复<br>47 node.master: true                                #节点能否被选举为master<br>51 node.data: true                                  #节点是否存储数据<br>107 index.number_of_shards: 5                       #索引分片的个数<br>111 index.number_of_replicas: 1                     #分片的副本个数<br>145 path.conf: /usr/local/elasticsearch/config/     #配置文件的路径<br>149 path.data: /data/es/data                        #数据目录路径<br>159 path.work: /data/es/worker                      #工作目录路径<br>163 path.logs:  /usr/local/elasticsearch/logs/      #日志文件路径<br>167 path.plugins:  /data/es/plugins                 #插件路径<br>184 bootstrap.mlockall: true                        #内存不向swap交换<br>232 http.enabled: true                              #启用http</p>
<p>4.创建相关目录</p>
<p>mkdir /data/es/{data,worker,plugins} -p</p>
<p>5.获取es服务管理脚本</p>
<p>​[root@es1 ~]# git clone <a href="https://github.com/elastic/elasticsearch-servicewrapper.git">https://github.com/elastic/elasticsearch-servicewrapper.git</a><br>[root@es1 ~]# mv elasticsearch-servicewrapper/service /usr/local/elasticsearch/bin/<br>[root@es1 ~]# /usr/local/elasticsearch/bin/service/elasticsearch install<br>Detected RHEL or Fedora:<br>Installing the Elasticsearch daemon..<br>[root@es1 ~]#<br>#这时就会在/etc/init.d/目录下安装上es的管理脚本啦</p>
<p>#修改其配置:<br>[root@es1 ~]#<br>set.default.ES_HOME=/usr/local/elasticsearch   #安装路径<br>set.default.ES_HEAP_SIZE=1024                  #jvm内存大小，根据实际环境调整即可</p>
<p>6.启动es ，并检查其服务是否正常</p>
<p>[root@es1 ~]# netstat -nlpt | grep -E “9200|”9300<br>tcp        0      0 0.0.0.0:9200                0.0.0.0:*                   LISTEN      1684/java<br>tcp        0      0 0.0.0.0:9300                0.0.0.0:*                   LISTEN      1684/java</p>
<p>访问<a href="http://192.168.2.18:9200/">http://192.168.2.18:9200/</a> 如果出现以下提示信息说明安装配置完成啦， <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/2.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/2.png" alt="2"></a> 7.es1节点好啦，我们直接把目录复制到es2</p>
<p>[root@es1 local]# scp -r elasticsearch-1.7.3  192.168.12.19:/usr/local/</p>
<p>[root@es2 local]# ln -sv elasticsearch-1.7.3 elasticsearch<br>[root@es2 local]# elasticsearch/bin/service/elasticsearch install</p>
<p>#es2只需要修改node.name即可，其他都与es1相同配置</p>
<p>8.安装es的管理插件 es官方提供一个用于管理es的插件，可清晰直观看到es集群的状态，以及对集群的操作管理，安装方法如下：</p>
<p>[root@es1 local]# /usr/local/elasticsearch/bin/plugin -i mobz/elasticsearch-head</p>
<p>安装好之后，访问方式为： <a href="http://192.168.2.18:9200/_plugin/head%EF%BC%8C%E7%94%B1%E4%BA%8E%E9%9B%86%E7%BE%A4%E4%B8%AD%E7%8E%B0%E5%9C%A8%E6%9A%82%E6%97%B6%E6%B2%A1%E6%9C%89%E6%95%B0%E6%8D%AE%EF%BC%8C%E6%89%80%E4%BB%A5%E6%98%BE%E7%A4%BA%E4%B8%BA%E7%A9%BA">http://192.168.2.18:9200/_plugin/head，由于集群中现在暂时没有数据，所以显示为空</a>, <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/3.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/3.png" alt="3"></a> &nbsp; &nbsp; &nbsp; <strong>此时，es集群的部署完成。</strong></p>
<h3 id="Logstash客户端安装配置"><a href="#Logstash客户端安装配置" class="headerlink" title="Logstash客户端安装配置;"></a>Logstash客户端安装配置;</h3><p>在webserve1上面安装Logstassh 1.downloads &nbsp;软件包 ，这里注意，Logstash是需要依赖java环境的，所以这里还是需要yum install -y java-1.8.0.</p>
<p>[root@webserver1 ~]# wget <a href="https://download.elastic.co/logstash/logstash/logstash-2.0.0.tar.gz">https://download.elastic.co/logstash/logstash/logstash-2.0.0.tar.gz</a><br>[root@webserver1 ~]# tar -xf logstash-2.0.0.tar.gz -C /usr/local<br>[root@webserver1 ~]# cd /usr/local/<br>[root@webserver1 local]# ln -sv logstash-2.0.0 logstash<br>[root@webserver1 local]# mkdir logs etc</p>
<p>2.提供logstash管理脚本，其中里面的配置路径可根据实际情况修改</p>
<p>#!/bin/bash<br>#chkconfig: 2345 55 24<br>#description: logstash service manager<br>#auto: Maoqiu Guo<br>FILE=’/usr/local/logstash/etc/*.conf’    #logstash配置文件<br>LOGBIN=’/usr/local/logstash/bin/logstash agent –verbose –config’  #指定logstash配置文件的命令<br>LOCK=’/usr/local/logstash/locks’         #用锁文件配合服务启动与关闭<br>LOGLOG=’–log /usr/local/logstash/logs/stdou.log’  #日志</p>
<p>START() {<br>	if [ -f $LOCK ];then<br>		echo -e “Logstash is already \033[32mrunning\033[0m, do nothing.”<br>	else<br>		echo -e “Start logstash service.\033[32mdone\033[m”<br>		nohup ${LOGBIN} ${FILE} ${LOGLOG} &amp;<br>		touch $LOCK<br>	fi<br>}</p>
<p>STOP() {<br>	if [ ! -f $LOCK ];then<br>		echo -e “Logstash is already stop, do nothing.”<br>	else<br>		echo -e “Stop logstash serivce \033[32mdone\033[m”<br>		rm -rf $LOCK<br>		ps -ef | grep logstash | grep -v “grep” | awk ‘{print $2}’ | xargs kill -s 9 &gt;/dev/null<br>	fi<br>}</p>
<p>STATUS() {<br>	ps aux | grep logstash | grep -v “grep” &gt;/dev/null<br>	if [ -f $LOCK ] &amp;&amp; [ $? -eq 0 ]; then<br>		echo -e “Logstash is: \033[32mrunning\033[0m…”<br>	else<br>		echo -e “Logstash is: \033[31mstopped\033[0m…”<br>	fi<br>}</p>
<p>TEST(){<br>	${LOGBIN} ${FILE} –configtest<br>}</p>
<p>case “$1” in<br>  start)<br>	START<br>	;;<br>  stop)<br>	STOP<br>	;;<br>  status)<br>	STATUS<br>	;;<br>  restart)<br>	STOP<br>        sleep 2<br>        START<br>	;;<br>  test)<br>	TEST<br>	;;<br>  *)<br>	echo “Usage: /etc/init.d/logstash (test|start|stop|status|restart)”<br>	;;<br>esac</p>
<p>3.Logstash 向es集群写数据 (1)编写一个logstash配置文件</p>
<p>[root@webserver1 etc]# cat logstash.conf<br>input {              #数据的输入从标准输入<br>  stdin {}<br>}</p>
<p>output {             #数据的输出我们指向了es集群<br>  elasticsearch {<br>    hosts =&gt; [“192.168.2.18:9200”,”192.168.2.19:9200”]　　　＃es主机的ip及端口<br>  }<br>}<br>[root@webserver1 etc]#</p>
<p>(2)检查配置文件是否有语法错</p>
<p>[root@webserver1 etc]# /usr/local/logstash/bin/logstash -f logstash.conf –configtest –verbose<br>Configuration OK<br>[root@webserver1 etc]# </p>
<p>(3)既然配置ok我们手动启动它，然后写点东西看能否写到es <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/4.png.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/4.png.png" alt="4.png"></a> ok.上图已经看到logstash已经可以正常的工作啦. ４.下面演示一下如何收集系统日志 将之前的配置文件修改如下所示内容，然后启动logstash服务就可以在web页面中看到messages的日志写入es，并且创建了一条索引</p>
<p>[root@webserver1 etc]# cat logstash.conf<br>input {　　　　　　　#这里的输入使用的文件，即日志文件messsages<br>  file {　　　<br>    path =&gt; “/var/log/messages”　　　＃这是日志文件的绝对路径<br>    start_position =&gt; “beginning”　＃这个表示从messages的第一行读取，即文件开始处<br>  }<br>}</p>
<p>output {　　　　＃输出到es<br>  elasticsearch {<br>    hosts =&gt; [“192.168.2.18:9200”,”192.168.2.19:9200”]<br>    index =&gt; “system-messages-%{+YYYY-MM}”　　＃这里将按照这个索引格式来创建索引<br>  }<br>}<br>[root@webserver1 etc]#</p>
<p>启动logstash后，我们来看head这个插件的web页面 <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/5.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/5.png" alt="5"></a> ok，系统日志我们已经成功的收集，并且已经写入到es集群中，那上面的演示是logstash直接将日志写入到es集群中的，这种场合我觉得如果量不是很大的话直接像上面已将将输出output定义到es集群即可，如果量大的话需要加上消息队列来缓解es集群的压力。前面已经提到了我这边之前使用的是单台redis作为消息队列，但是redis不能作为list类型的集群，也就是redis单点的问题没法解决，所以这里我选用了kafka ;下面就在三台server上面安装kafka集群</p>
<h3 id="Kafka集群安装配置"><a href="#Kafka集群安装配置" class="headerlink" title="Kafka集群安装配置;"></a>Kafka集群安装配置;</h3><p>在搭建kafka集群时，需要提前安装zookeeper集群，当然kafka已经自带zookeeper程序只需要解压并且安装配置就行了 kafka1上面的配置： 1.获取软件包.官网：<a href="http://kafka.apache.org/">http://kafka.apache.org</a></p>
<p>[root@kafka1 ~]# wget <a href="http://mirror.rise.ph/apache/kafka/0.8.2.1/kafka_2.11-0.8.2.1.tgz">http://mirror.rise.ph/apache/kafka/0.8.2.1/kafka_2.11-0.8.2.1.tgz</a><br>[root@kafka1 ~]# tar -xf kafka_2.11-0.8.2.1.tgz -C /usr/local/<br>[root@kafka1 ~]# cd /usr/local/<br>[root@kafka1 local]# ln -sv kafka_2.11-0.8.2.1 kafka</p>
<p>2.配置zookeeper集群，修改配置文件</p>
<p>[root@kafka1 ~]# vim /usr/local/kafka/config/zookeeper.propertie<br>dataDir=/data/zookeeper<br>clientPort=2181<br>tickTime=2000<br>initLimit=20<br>syncLimit=10<br>server.2=192.168.2.22:2888:3888<br>server.3=192.168.2.23:2888:3888<br>server.4=192.168.2.24:2888:3888</p>
<p>＃说明：<br>tickTime: 这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。<br>2888端口：表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；<br>3888端口：表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</p>
<p>3.创建zookeeper所需要的目录</p>
<p>[root@kafka1 ~]# mkdir /data/zookeeper</p>
<p>4.在/data/zookeeper目录下创建myid文件，里面的内容为数字，用于标识主机，如果这个文件没有的话，zookeeper是没法启动的哦</p>
<p>[root@kafka1 ~]# echo 2 &gt; /data/zookeeper/myid</p>
<p>以上就是zookeeper集群的配置，下面等我配置好kafka之后直接复制到其他两个节点即可 5.kafka配置</p>
<p>[root@kafka1 ~]# vim /usr/local/kafka/config/server.properties<br>broker.id=2    　　　　    ＃　唯一，填数字，本文中分别为2/3/4<br>prot=9092　　　　　　　     ＃　这个broker监听的端口　<br>host.name=192.168.2.22　  ＃　唯一，填服务器IP<br>log.dir=/data/kafka-logs  #  该目录可以不用提前创建，在启动时自己会创建<br>zookeeper.connect=192.168.2.22:2181,192.168.2.23:2181,192.168.2.24:2181　　＃这个就是zookeeper的ip及端口<br>num.partitions=16         # 需要配置较大 分片影响读写速度<br>log.dirs=/data/kafka-logs # 数据目录也要单独配置磁盘较大的地方<br>log.retention.hours=168   # 时间按需求保留过期时间 避免磁盘满</p>
<p>6.将kafka(zookeeper)的程序目录全部拷贝至其他两个节点</p>
<p>[root@kafka1 ~]# scp -r /usr/local/kafka 192.168.2.23:/usr/local/<br>[root@kafka1 ~]# scp -r /usr/local/kafka 192.168.2.24:/usr/local/</p>
<p>7.修改两个借点的配置，注意这里除了以下两点不同外，都是相同的配置</p>
<p>（1）zookeeper的配置<br>mkdir /data/zookeeper<br>echo “x” &gt; /data/zookeeper/myid<br>（2）kafka的配置<br>broker.id=2<br>host.name=192.168.2.22</p>
<p>8.修改完毕配置之后我们就可以启动了，这里先要启动zookeeper集群，才能启动kafka 我们按照顺序来，kafka1 –&gt; kafka2 –&gt;kafka3</p>
<p>[root@kafka1 ~]# /usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties &amp;   #zookeeper启动命令<br>[root@kafka1 ~]# /usr/local/kafka/bin/zookeeper-server-stop.sh                                                   #zookeeper停止的命令</p>
<p>注意，如果zookeeper有问题 nohup的日志文件会非常大，把磁盘占满，这个zookeeper服务可以通过自己些服务脚本来管理服务的启动与关闭。 后面两台执行相同操作，在启动过程当中会出现以下报错信息</p>
<p>[2015-11-13 19:18:04,225] WARN Cannot open channel to 3 at election address /192.168.2.23:3888 (org.apache.zookeeper.server.quorum.QuorumCnxManager)<br>java.net.ConnectException: Connection refused<br>	at java.net.PlainSocketImpl.socketConnect(Native Method)<br>	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)<br>	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)<br>	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)<br>	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)<br>	at java.net.Socket.connect(Socket.java:589)<br>	at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:368)<br>	at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectAll(QuorumCnxManager.java:402)<br>	at org.apache.zookeeper.server.quorum.FastLeaderElection.lookForLeader(FastLeaderElection.java:840)<br>	at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:762)<br>[2015-11-13 19:18:04,232] WARN Cannot open channel to 4 at election address /192.168.2.24:3888 (org.apache.zookeeper.server.quorum.QuorumCnxManager)<br>java.net.ConnectException: Connection refused<br>	at java.net.PlainSocketImpl.socketConnect(Native Method)<br>	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)<br>	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)<br>	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)<br>	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)<br>	at java.net.Socket.connect(Socket.java:589)<br>	at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:368)<br>	at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectAll(QuorumCnxManager.java:402)<br>	at org.apache.zookeeper.server.quorum.FastLeaderElection.lookForLeader(FastLeaderElection.java:840)<br>	at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:762)<br>[2015-11-13 19:18:04,233] INFO Notification time out: 6400 (org.apache.zookeeper.server.quorum.FastLeaderElection)</p>
<p>由于zookeeper集群在启动的时候，每个结点都试图去连接集群中的其它结点，先启动的肯定连不上后面还没启动的，所以上面日志前面部分的异常是可以忽略的。通过后面部分可以看到，集群在选出一个Leader后，最后稳定了。 其他节点也可能会出现类似的情况，属于正常。 9.zookeeper服务检查</p>
<p>[root@kafka1~]#  netstat -nlpt | grep -E “2181|2888|3888”<br>tcp        0      0 192.168.2.24:3888           0.0.0.0:*                   LISTEN      1959/java<br>tcp        0      0 0.0.0.0:2181                0.0.0.0:*                   LISTEN      1959/java                       </p>
<p>[root@kafka2 ~]#  netstat -nlpt | grep -E “2181|2888|3888”<br>tcp        0      0 192.168.2.23:3888           0.0.0.0:*                   LISTEN      1723/java<br>tcp        0      0 0.0.0.0:2181                0.0.0.0:*                   LISTEN      1723/java           </p>
<p>[root@kafka3 ~]#  netstat -nlpt | grep -E “2181|2888|3888”<br>tcp        0      0 192.168.2.24:3888           0.0.0.0:*                   LISTEN      950/java<br>tcp        0      0 0.0.0.0:2181                0.0.0.0:*                   LISTEN      950/java<br>tcp        0      0 192.168.2.24:2888           0.0.0.0:*                   LISTEN      950/java            </p>
<p>#可以看出，如果哪台是Leader,那么它就拥有2888这个端口</p>
<p>ok. &nbsp;这时候zookeeper集群已经启动起来了，下面启动kafka，也是依次按照顺序启动</p>
<p>[root@kafka1 ~]# nohup /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties &amp;   #kafka启动的命令<br>[root@kafka1 ~]#  /usr/local/kafka/bin/kafka-server-stop.sh                                                         #kafka停止的命令</p>
<p>注意，跟zookeeper服务一样，如果kafka有问题 nohup的日志文件会非常大,把磁盘占满，这个kafka服务同样可以通过自己些服务脚本来管理服务的启动与关闭。 此时三台上面的zookeeper及kafka都已经启动完毕，来检测以下吧 (1)建立一个主题</p>
<p>[root@kafka1 ~]# /usr/local/kafka/bin/kafka-topics.sh –create –zookeeper localhost:2181 –replication-factor 3 –partitions 1 –topic summer<br>#注意：factor大小不能超过broker数</p>
<p>(2)查看有哪些主题已经创建</p>
<p>[root@kafka1 ~]# /usr/local/kafka/bin/kafka-topics.sh –list –zookeeper 192.168.2.22:2181   #列出集群中所有的topic<br>summer  #已经创建成功</p>
<p>(3)查看summer这个主题的详情</p>
<p>[root@kafka1 ~]# /usr/local/kafka/bin/kafka-topics.sh –describe –zookeeper 192.168.2.22:2181 –topic summer<br>Topic:summer	PartitionCount:1	ReplicationFactor:3	Configs:<br>	Topic: summer	Partition: 0	Leader: 2	Replicas: 2,4,3	Isr: 2,4,3</p>
<p>#主题名称：summer<br>#Partition:只有一个，从0开始<br>#leader ：id为2的broker<br>#Replicas 副本存在于broker id为2,3,4的上面<br>#Isr:活跃状态的broker</p>
<p>(4)发送消息，这里使用的是生产者角色</p>
<p>[root@kafka1 ~]# /bin/bash /usr/local/kafka/bin/kafka-console-producer.sh –broker-list 192.168.2.22:9092 –topic summer<br>This is a messages<br>welcome to kafka    </p>
<p>(5)接收消息，这里使用的是消费者角色</p>
<p>[root@kafka2 ~]# /usr/local/kafka/bin/kafka-console-consumer.sh –zookeeper  192.168.2.24:2181 –topic summer –from-beginning<br>This is a messages<br>welcome to kafka</p>
<p>如果能够像上面一样能够接收到生产者发过来的消息，那说明基于kafka的zookeeper集群就成功啦。 10，下面我们将webserver1上面的logstash的输出改到kafka上面，将数据写入到kafka中 (1)修改webserver1上面的logstash配置，如下所示：各个参数可以到<a href="https://www.elastic.co/">官网</a>查询.</p>
<p>root@webserver1 etc]# cat logstash.conf<br>input {             #这里的输入还是定义的是从日志文件输入<br>  file {<br>    type =&gt; “system-message”<br>    path =&gt; “/var/log/messages”<br>    start_position =&gt; “beginning”<br>  }<br>}</p>
<p>output {<br>    #stdout { codec =&gt; rubydebug }   #这是标准输出到终端，可以用于调试看有没有输出，注意输出的方向可以有多个<br>    kafka {   #输出到kafka<br>      bootstrap_servers =&gt; “192.168.2.22:9092,192.168.2.23:9092,192.168.2.24:9092”   #他们就是生产者<br>      topic_id =&gt; “system-messages”  #这个将作为主题的名称，将会自动创建<br>      compression_type =&gt; “snappy”   #压缩类型<br>    }<br>}<br>[root@webserver1 etc]#</p>
<p>(2)配置检测</p>
<p>[root@webserver1 etc]# /usr/local/logstash/bin/logstash -f logstash.conf –configtest –verbose<br>Configuration OK<br>[root@webserver1 etc]# </p>
<p>(2)启动Logstash，这里我直接在命令行执行即可</p>
<p>[root@webserver1 etc]# /usr/local/logstash/bin/logstash -f logstash.conf</p>
<p>(3)验证数据是否写入到kafka，这里我们检查是否生成了一个叫system-messages的主题</p>
<p>[root@kafka1 ~]# /usr/local/kafka/bin/kafka-topics.sh –list –zookeeper 192.168.2.22:2181<br>summer<br>system-messages   #可以看到这个主题已经生成了</p>
<p>#再看看这个主题的详情:<br>[root@kafka1 ~]# /usr/local/kafka/bin/kafka-topics.sh –describe –zookeeper 192.168.2.22:2181 –topic system-messages<br>Topic:system-messages	PartitionCount:16	ReplicationFactor:1	Configs:<br>	Topic: system-messages	Partition: 0	Leader: 2	Replicas: 2	Isr: 2<br>	Topic: system-messages	Partition: 1	Leader: 3	Replicas: 3	Isr: 3<br>	Topic: system-messages	Partition: 2	Leader: 4	Replicas: 4	Isr: 4<br>	Topic: system-messages	Partition: 3	Leader: 2	Replicas: 2	Isr: 2<br>	Topic: system-messages	Partition: 4	Leader: 3	Replicas: 3	Isr: 3<br>	Topic: system-messages	Partition: 5	Leader: 4	Replicas: 4	Isr: 4<br>	Topic: system-messages	Partition: 6	Leader: 2	Replicas: 2	Isr: 2<br>	Topic: system-messages	Partition: 7	Leader: 3	Replicas: 3	Isr: 3<br>	Topic: system-messages	Partition: 8	Leader: 4	Replicas: 4	Isr: 4<br>	Topic: system-messages	Partition: 9	Leader: 2	Replicas: 2	Isr: 2<br>	Topic: system-messages	Partition: 10	Leader: 3	Replicas: 3	Isr: 3<br>	Topic: system-messages	Partition: 11	Leader: 4	Replicas: 4	Isr: 4<br>	Topic: system-messages	Partition: 12	Leader: 2	Replicas: 2	Isr: 2<br>	Topic: system-messages	Partition: 13	Leader: 3	Replicas: 3	Isr: 3<br>	Topic: system-messages	Partition: 14	Leader: 4	Replicas: 4	Isr: 4<br>	Topic: system-messages	Partition: 15	Leader: 2	Replicas: 2	Isr: 2<br>[root@kafka1 ~]# </p>
<p>可以看出，这个主题生成了16个分区，每个分区都有对应自己的Leader，但是我想要有10个分区，3个副本如何办？还是跟我们上面一样命令行来创建主题就行，当然对于logstash输出的我们也可以提前先定义主题，然后启动logstash 直接往定义好的主题写数据就行啦，命令如下：</p>
<p>[root@kafka1 ~]# /usr/local/kafka/bin/kafka-topics.sh –create –zookeeper 192.168.2.22:2181 –replication-factor 3 –partitions 10 –topic TOPIC_NAME</p>
<p>好了，我们将logstash收集到的数据写入到了kafka中了，在实验过程中我使用while脚本测试了如果不断的往kafka写数据的同时停掉两个节点，数据写入没有任何问题。 那如何将数据从kafka中读取然后给我们的es集群呢？那下面我们在kafka集群上安装Logstash，安装步骤不再赘述；三台上面的logstash 的配置如下，作用是将kafka集群的数据读取然后转交给es集群，这里为了测试我让他新建一个索引文件，注意这里的输入日志还是messages，主题名称还是“system-messages”</p>
<p>[root@kafka1 etc]# more logstash.conf<br>input {<br>    kafka {<br>        zk_connect =&gt; “192.168.2.22:2181,192.168.2.23:2181,192.168.2.24:2181”   #消费者们<br>        topic_id =&gt; “system-messages”<br>        codec =&gt; plain<br>        reset_beginning =&gt; false<br>        consumer_threads =&gt; 5<br>        decorate_events =&gt; true<br>    }<br>}</p>
<p>output {<br>    elasticsearch {<br>      hosts =&gt; [“192.168.2.18:9200”,”192.168.2.19:9200”]<br>      index =&gt; “test-system-messages-%{+YYYY-MM}”           #为了区分之前实验，我这里新生成的所以名字为“test-system-messages-%{+YYYY-MM}”<br>  }<br>  }</p>
<p>在三台kafka上面启动Logstash，注意我这里是在命令行启动的；</p>
<p>[root@kafka1 etc]# pwd<br>/usr/local/logstash/etc<br>[root@kafka1 etc]# /usr/local/logstash/bin/logstash -f logstash.conf<br>[root@kafka2 etc]# pwd<br>/usr/local/logstash/etc<br>[root@kafka2 etc]# /usr/local/logstash/bin/logstash -f logstash.conf<br>[root@kafka3 etc]# pwd<br>/usr/local/logstash/etc<br>[root@kafka3 etc]# /usr/local/logstash/bin/logstash -f logstash.conf </p>
<p>在webserver1上写入测试内容，即webserver1上面利用message这个文件来测试，我先将其清空，然后启动</p>
<p>[root@webserver1 etc]# &gt;/var/log/messages<br>[root@webserver1 etc]# echo “我将通过kafka集群达到es集群哦^0^” &gt;&gt; /var/log/messages<br>#启动logstash,让其读取messages中的内容</p>
<p>下图为我在客户端写入到kafka集群的同时也将其输入到终端，这里写入了三条内容 <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/6.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/6.png" alt="6"></a> 而下面三张图侧可以看出，三台Logstash 很平均的从kafka集群当中读取出来了日志内容 <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/7.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/7.png" alt="7"></a> <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/9.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/9.png" alt="9"></a> <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/8.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/8.png" alt="8"></a> 再来看看我们的es管理界面 <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/10.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/10.png" alt="10"></a> ok ,看到了吧， 流程差不多就是下面 酱紫咯 <a href="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/111.png"><img src="https://qcloud.coding.net/u/guomaoqiu/p/guomaoqiu/git/raw/master/uploads/2015/11/111.png" alt="111"></a> 由于篇幅较长，我将 4.Kibana部署; 5.Nginx负载均衡Kibana请求; 6.案例：nginx日志收集以及MySQL慢日志收集; 7.Kibana报表基本使用; 放到下一篇博客。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.sctux.cc">NoardGuo-Ops</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.sctux.cc/2015/11/14/elkkafka-e4-bc-81-e4-b8-9a-e6-97-a5-e5-bf-97-e6-94-b6-e9-9b-86-e5-b9-b3-e5-8f-b0-e4-b8-80/">https://blog.sctux.cc/2015/11/14/elkkafka-e4-bc-81-e4-b8-9a-e6-97-a5-e5-bf-97-e6-94-b6-e9-9b-86-e5-b9-b3-e5-8f-b0-e4-b8-80/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.sctux.cc" target="_blank">OpsThoughts</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ELK/">ELK</a><a class="post-meta__tags" href="/tags/kafka/">kafka</a><a class="post-meta__tags" href="/tags/zookeeper/">zookeeper</a></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src="/img/wechat.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/zhifubao.png" target="_blank"><img class="post-qr-code-img" src="/img/zhifubao.png" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2015/11/14/elkkafka-e4-bc-81-e4-b8-9a-e6-97-a5-e5-bf-97-e6-94-b6-e9-9b-86-e5-b9-b3-e5-8f-b0-e4-ba-8c/" title="ELK+Kafka 企业日志收集平台(二)"><img class="cover" src="https://images.unsplash.com/photo-1639762681057-408e52192e55?w=800&amp;h=400" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">ELK+Kafka 企业日志收集平台(二)</div></div><div class="info-2"><div class="info-item-1">上篇博文主要总结了一下elk、基于kafka的zookeeper集群搭建，以及系统日志通过zookeeper集群达到我们集群的整个过程。下面我们接着下面这个未完成的几个主题 4.Kibana部署; 5.Nginx负载均衡Kibana请求; 6.案例：nginx日志收集以及MySQL慢日志收集; 7.Kibana报表基本使用; &nbsp; Kibana的部署;Kibana的作用，想必大家都知道了就是一个展示工具，报表内容非常的丰富； 下面我们在两台es上面搭建两套kibana 1.获取kibana软件包 [root@es1 ~]# wget https://download.elastic.co/kibana/kibana/kibana-4.1.2-linux-x64.tar.gz[root@es1 ~]# tar -xf kibana-4.2.0-linux-x64.tar.gz -C /usr/local/ 2.修改配置文件 [root@es1 ~]# cd /usr/local/[root@es1 local]# ln -sv kibana-4.1.2-linux-x64 ...</div></div></div></a><a class="pagination-related" href="/2015/10/23/e6-b8-85-e7-90-86elasticsearch-e7-9a-84-e7-b4-a2-e5-bc-95/" title="清理Elasticsearch的索引"><img class="cover" src="https://images.unsplash.com/photo-1551650975-87deedd944c3?w=800&amp;h=400" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">清理Elasticsearch的索引</div></div><div class="info-2"><div class="info-item-1">最近在使用 logstash来做日志收集 并用 elasticsearch来搜索，因为日志没有进行过滤，没几天就发现elasticsearch的索引文件大的吓人，之前还真没清理过。其实要说清理 也简单，直接到 elasticsearch data文件夹里删掉就行了，但怎么也得做的有点技术含量不是？ 上网站看了看文档，其实也挺简单一条命令就行了  1,  # curl -XDELETE ‘http://localhost:9200/logstash-*’ 2,  清理掉了所有的索引文件，我发现curl删除比rm删除要快出很多 下面是主页上的详细介绍，其他部分可以自己看， http://www.elasticsearch.org/guide/reference/api/delet </div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2015/11/14/elkkafka-e4-bc-81-e4-b8-9a-e6-97-a5-e5-bf-97-e6-94-b6-e9-9b-86-e5-b9-b3-e5-8f-b0-e4-ba-8c/" title="ELK+Kafka 企业日志收集平台(二)"><img class="cover" src="https://images.unsplash.com/photo-1639762681057-408e52192e55?w=800&h=400" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2015-11-14</div><div class="info-item-2">ELK+Kafka 企业日志收集平台(二)</div></div><div class="info-2"><div class="info-item-1">上篇博文主要总结了一下elk、基于kafka的zookeeper集群搭建，以及系统日志通过zookeeper集群达到我们集群的整个过程。下面我们接着下面这个未完成的几个主题 4.Kibana部署; 5.Nginx负载均衡Kibana请求; 6.案例：nginx日志收集以及MySQL慢日志收集; 7.Kibana报表基本使用; &nbsp; Kibana的部署;Kibana的作用，想必大家都知道了就是一个展示工具，报表内容非常的丰富； 下面我们在两台es上面搭建两套kibana 1.获取kibana软件包 [root@es1 ~]# wget https://download.elastic.co/kibana/kibana/kibana-4.1.2-linux-x64.tar.gz[root@es1 ~]# tar -xf kibana-4.2.0-linux-x64.tar.gz -C /usr/local/ 2.修改配置文件 [root@es1 ~]# cd /usr/local/[root@es1 local]# ln -sv kibana-4.1.2-linux-x64 ...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">NoardGuo-Ops</div><div class="author-info-description">Happiness is not something ready-made. It comes from your own actions💪🏻.</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">99</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">93</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">30</div></a></div><a id="card-info-btn" href="https://github.com/guomaoqiu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/guomaoqiu" target="_blank" title="Github"><i class="fab fa-github" style="color: #fcfcfc;"></i></a><a class="social-icon" href="mailto:guomaoqiu@icloud.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #663399;"></i></a><a class="social-icon" href="https://t.me/noardguo_devops" target="_blank" title="TG"><i class="fa-brands fa-telegram" style="color: #00ff99;"></i></a><a class="social-icon" href="weixin://NoardGuo-Ops" target="_blank" title="WeChat"><i class="fa-brands fa-weixin" style="color: #b197fc;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%EF%BC%9A"><span class="toc-number">1.</span> <span class="toc-text">背景：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ELK%E6%9E%B6%E6%9E%84%E6%8B%93%E6%89%91%EF%BC%9A"><span class="toc-number">2.</span> <span class="toc-text">ELK架构拓扑：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ES%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="toc-number">3.</span> <span class="toc-text">ES集群安装配置;</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Logstash%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="toc-number">4.</span> <span class="toc-text">Logstash客户端安装配置;</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="toc-number">5.</span> <span class="toc-text">Kafka集群安装配置;</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/08/29/%E6%B1%82%E8%81%8C%E5%B8%96/" title="求职-系统运维/SRE方向"><img src="https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&amp;h=400" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="求职-系统运维/SRE方向"/></a><div class="content"><a class="title" href="/2025/08/29/%E6%B1%82%E8%81%8C%E5%B8%96/" title="求职-系统运维/SRE方向">求职-系统运维/SRE方向</a><time datetime="2025-08-28T16:01:01.000Z" title="发表于 2025-08-29 00:01:01">2025-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/23/Docker%E6%9E%84%E5%BB%BA%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E5%B9%B3%E5%8F%B0EFK-TLS/" title="Docker构建日志收集平台EFK(TLS)"><img src="https://images.unsplash.com/photo-1639762681057-408e52192e55?w=800&amp;h=400" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Docker构建日志收集平台EFK(TLS)"/></a><div class="content"><a class="title" href="/2024/07/23/Docker%E6%9E%84%E5%BB%BA%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E5%B9%B3%E5%8F%B0EFK-TLS/" title="Docker构建日志收集平台EFK(TLS)">Docker构建日志收集平台EFK(TLS)</a><time datetime="2024-07-23T01:56:27.000Z" title="发表于 2024-07-23 09:56:27">2024-07-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/16/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8ElastAlert2%E5%AF%B9ES%E4%B8%AD%E7%9A%84%E6%97%A5%E5%BF%97%E5%88%9B%E5%BB%BA%E5%91%8A%E8%AD%A6/" title="如何利用ElastAlert2对ES中的日志创建告警"><img src="https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&amp;h=400" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何利用ElastAlert2对ES中的日志创建告警"/></a><div class="content"><a class="title" href="/2024/07/16/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8ElastAlert2%E5%AF%B9ES%E4%B8%AD%E7%9A%84%E6%97%A5%E5%BF%97%E5%88%9B%E5%BB%BA%E5%91%8A%E8%AD%A6/" title="如何利用ElastAlert2对ES中的日志创建告警">如何利用ElastAlert2对ES中的日志创建告警</a><time datetime="2024-07-16T09:56:39.000Z" title="发表于 2024-07-16 17:56:39">2024-07-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/09/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8Python%E8%8E%B7%E5%8F%96%E6%89%80%E6%9C%89pod%E5%AE%B9%E5%99%A8%E7%8A%B6%E6%80%81/" title="如何利用Python获取所有pod容器状态"><img src="https://images.unsplash.com/photo-1573164713714-d95e436ab8d6?w=800&amp;h=400" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="如何利用Python获取所有pod容器状态"/></a><div class="content"><a class="title" href="/2024/07/09/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8Python%E8%8E%B7%E5%8F%96%E6%89%80%E6%9C%89pod%E5%AE%B9%E5%99%A8%E7%8A%B6%E6%80%81/" title="如何利用Python获取所有pod容器状态">如何利用Python获取所有pod容器状态</a><time datetime="2024-07-09T09:38:00.000Z" title="发表于 2024-07-09 17:38:00">2024-07-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/05/10/K8S%E4%B8%ADMySQL%E4%BD%BF%E7%94%A8NFS%E6%8C%82%E8%BD%BD%E7%9A%84%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/" title="K8S中MySQL使用NFS挂载的异常问题处理"><img src="https://images.unsplash.com/photo-1635070041078-e363dbe005cb?w=800&amp;h=400" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="K8S中MySQL使用NFS挂载的异常问题处理"/></a><div class="content"><a class="title" href="/2024/05/10/K8S%E4%B8%ADMySQL%E4%BD%BF%E7%94%A8NFS%E6%8C%82%E8%BD%BD%E7%9A%84%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/" title="K8S中MySQL使用NFS挂载的异常问题处理">K8S中MySQL使用NFS挂载的异常问题处理</a><time datetime="2024-05-10T12:58:02.000Z" title="发表于 2024-05-10 20:58:02">2024-05-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/12/Prometheus-Consul%E5%AE%9E%E7%8E%B0%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%AE%BF%E4%B8%BB%E6%9C%BA-%E5%AE%B9%E5%99%A8%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/" title="Prometheus+Consul实现企业级宿主机+容器监控告警"><img src="https://images.unsplash.com/photo-1581094794329-c8112a89af12?w=800&amp;h=400" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Prometheus+Consul实现企业级宿主机+容器监控告警"/></a><div class="content"><a class="title" href="/2022/09/12/Prometheus-Consul%E5%AE%9E%E7%8E%B0%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%AE%BF%E4%B8%BB%E6%9C%BA-%E5%AE%B9%E5%99%A8%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/" title="Prometheus+Consul实现企业级宿主机+容器监控告警">Prometheus+Consul实现企业级宿主机+容器监控告警</a><time datetime="2022-09-12T06:45:26.000Z" title="发表于 2022-09-12 14:45:26">2022-09-12</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800&amp;h=400);"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2013 - 2025 By NoardGuo-Ops</span><span class="framework-info"><span>框架 </span><a href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div><div class="footer_custom_text">Hi, welcome to my <a href="https://blog.sctux.cc/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"></div><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>